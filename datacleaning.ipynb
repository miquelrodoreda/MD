{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/miquelrodoreda/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/miquelrodoreda/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'cuisine': 102 valores diferentes\n",
      "['Steakhouse' 'Mediterranean' 'Barbecue' 'Spanish' 'Seafood' 'European'\n",
      " 'Catalan' 'Cafe' 'Contemporary' 'Mexican' 'Latin' 'South American'\n",
      " 'Central American' 'Fast food' 'Healthy' 'Italian' 'Pizza' 'Grill' 'Bar'\n",
      " 'Pub' 'Japanese' 'Sushi' 'Asian' 'Deli' 'Gastropub' 'American' 'French'\n",
      " 'International' 'Fusion' 'Diner' 'Argentinian' 'Japanese Fusion'\n",
      " 'Wine Bar' 'Neapolitan' 'Campania' 'Southern-Italian' 'Brew Pub' 'Soups'\n",
      " 'Chinese' 'Lebanese' 'Middle Eastern' 'Romana' 'Lazio' 'Central-Italian'\n",
      " 'Central Asian' 'African' 'Ethiopian' 'German' 'Central European'\n",
      " 'Polish' 'Chilean' 'Street Food' 'British' 'Indian' 'Peruvian' 'Thai'\n",
      " 'Caucasian' 'Greek' 'Hawaiian' 'Balti' 'Sardinian' 'Russian' 'Caribbean'\n",
      " 'Venezuelan' 'Portuguese' 'Taiwanese' 'Yunnan' 'Sicilian' 'Brazilian'\n",
      " 'Azerbaijani' 'Korean' 'Vietnamese' 'Indonesian' 'Moroccan' 'Philippine'\n",
      " 'Singaporean' 'Dining bars' 'Israeli' 'Tuscan' 'Belgian' 'Pakistani'\n",
      " 'Persian' 'Southwestern' 'Beer restaurants' 'Arabic' 'Malaysian' 'Irish'\n",
      " 'Northern-Italian' 'Dutch' 'Nepalese' 'Cambodian' 'Hungarian' 'Turkish'\n",
      " 'Jamaican' 'Colombian' 'Swiss' 'Medicinal foods' 'Cuban' 'Georgian'\n",
      " 'Tibetan' 'Ecuadorean' 'Native American']\n",
      "Valores únicos en 'price_level': 3 valores diferentes\n",
      "['€€-€€€' '€' '€€€€']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/tripadvisor-barcelona-restaurants-100reviews-2025-02-13.csv')\n",
    "\n",
    "cuisines = df['cuisines'].dropna().apply(lambda x: [cuisine.strip() for cuisine in x.split(',')]).explode()\n",
    "\n",
    "unique_cuisines = cuisines.unique()\n",
    "\n",
    "print(f\"Valores únicos en 'cuisine': {len(unique_cuisines)} valores diferentes\")\n",
    "print(unique_cuisines)\n",
    "\n",
    "price_level = df['price_level'].unique()\n",
    "print(f\"Valores únicos en 'price_level': {len(price_level)} valores diferentes\")\n",
    "print(price_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_cuisines = [\n",
    "    'Spanish', 'French', 'Italian', 'Mexican', 'Latin', 'South American',\n",
    "    'Central American', 'Italian', 'American', 'Japanese', 'Chinese', \n",
    "    'Lebanese', 'Middle Eastern', 'Argentinian', 'Japanese Fusion', \n",
    "    'Neapolitan', 'Campania', 'Southern-Italian', 'Chinese', 'Lebanese', \n",
    "    'Polish', 'Chilean', 'British', 'Indian', 'Peruvian', 'Thai', 'Greek', \n",
    "    'Hawaiian', 'Sardinian', 'Russian', 'Caribbean', 'Venezuelan', 'Portuguese', \n",
    "    'Taiwanese', 'Brazilian', 'Azerbaijani', 'Korean', 'Vietnamese', 'Indonesian', \n",
    "    'Moroccan', 'Philippine', 'Israeli', 'Pakistani', 'Persian', 'Turkish', \n",
    "    'Colombian', 'Cuban', 'Georgian', 'Ecuadorean', 'Native American'\n",
    "]\n",
    "\n",
    "def extract_last_location(loc_str):\n",
    "    try:\n",
    "        loc_list = ast.literal_eval(loc_str)\n",
    "        return loc_list[-1] if loc_list else None\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "\n",
    "df['location'] = df['original_location'].apply(extract_last_location)\n",
    "\n",
    "df['cuisine_nation'] = df['cuisines'].apply(lambda x: [cuisine.strip() for cuisine in x.split(',')] if isinstance(x, str) else None)\n",
    "df['cuisine_nation'] = df['cuisine_nation'].apply(lambda x: next((c for c in x if c in valid_cuisines), None) if x else None)\n",
    "\n",
    "def extract_certificate_of_excellence(award_str):\n",
    "    if isinstance(award_str, str):\n",
    "        index = award_str.find('Certificate of Excellence')\n",
    "        if index != -1:  # Si encontramos 'Certificate of Excellence'\n",
    "            return award_str[index:index+30]  # 'Certificate of Excellence' tiene 26 caracteres\n",
    "    return None\n",
    "\n",
    "df['last_certificate_excellence'] = df['awards'].apply(lambda x: extract_certificate_of_excellence(x) if isinstance(x, str) else None)\n",
    "\n",
    "df['top_tag'] = df['top_tags'].apply(lambda x: x.split(',')[0] if isinstance(x, str) else None)\n",
    "\n",
    "columns_to_keep = [\n",
    "    'price_level', 'vegan_options', 'gluten_free', \n",
    "    'open_days_per_week', 'avg_rating', 'total_reviews_count', \n",
    "    'food', 'service', 'atmosphere', 'excellent', 'location', \n",
    "    'last_certificate_excellence', 'cuisine_nation', 'top_tag'\n",
    "]\n",
    "\n",
    "df_filtered = df[columns_to_keep]\n",
    "\n",
    "df_filtered.to_csv('./dataset/columnrefactor.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en 'cuisine': 39 valores diferentes\n",
      "['Spanish' None 'Mexican' 'Italian' 'Japanese' 'American' 'French' 'Latin'\n",
      " 'Japanese Fusion' 'Argentinian' 'Chinese' 'Lebanese' 'Polish' 'Chilean'\n",
      " 'British' 'Indian' 'Peruvian' 'Thai' 'Greek' 'Hawaiian' 'Russian'\n",
      " 'Caribbean' 'Portuguese' 'Brazilian' 'Azerbaijani' 'Philippine' 'Korean'\n",
      " 'Vietnamese' 'Middle Eastern' 'Venezuelan' 'Southern-Italian' 'Pakistani'\n",
      " 'Indonesian' 'Moroccan' 'Turkish' 'Colombian' 'Central American'\n",
      " 'South American' 'Cuban']\n",
      "\n",
      "Valores únicos en 'last_certificate_excellence': 11 valores diferentes\n",
      "['Certificate of Excellence 2016' None 'Certificate of Excellence 2020'\n",
      " 'Certificate of Excellence 2019' 'Certificate of Excellence 2018'\n",
      " 'Certificate of Excellence 2015' 'Certificate of Excellence 2017'\n",
      " 'Certificate of Excellence 2013' 'Certificate of Excellence 2014'\n",
      " 'Certificate of Excellence 2012' 'Certificate of Excellence 2011']\n",
      "\n",
      "Valores únicos en 'top_tag': 3 valores diferentes\n",
      "['Mid-range' 'Cheap Eats' 'Fine Dining']\n"
     ]
    }
   ],
   "source": [
    "cuisine_unique_values = df['cuisine_nation'].unique()\n",
    "award_unique_values = df['last_certificate_excellence'].unique()\n",
    "top_tag_unique_values = df['top_tag'].unique()\n",
    "\n",
    "print(f\"Valores únicos en 'cuisine': {len(cuisine_unique_values)} valores diferentes\")\n",
    "print(cuisine_unique_values)\n",
    "\n",
    "print(f\"\\nValores únicos en 'last_certificate_excellence': {len(award_unique_values)} valores diferentes\")\n",
    "print(award_unique_values)\n",
    "\n",
    "print(f\"\\nValores únicos en 'top_tag': {len(top_tag_unique_values)} valores diferentes\")\n",
    "print(top_tag_unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Null Count  Null Percentage\n",
      "price_level                           0         0.000000\n",
      "vegan_options                         0         0.000000\n",
      "gluten_free                           0         0.000000\n",
      "open_days_per_week                  444        11.102776\n",
      "avg_rating                            0         0.000000\n",
      "total_reviews_count                   0         0.000000\n",
      "food                                  4         0.100025\n",
      "service                               3         0.075019\n",
      "atmosphere                         1157        28.932233\n",
      "excellent                             0         0.000000\n",
      "location                              0         0.000000\n",
      "last_certificate_excellence        1119        27.981995\n",
      "cuisine_nation                      630        15.753938\n",
      "top_tag                               0         0.000000\n",
      "Total missing data (%):  5.996141892616011\n"
     ]
    }
   ],
   "source": [
    "## Count nulls\n",
    "\n",
    "def null_summary(df):\n",
    "    null_counts = df.isnull().sum() \n",
    "    null_percentage = (null_counts / len(df)) * 100 \n",
    "    null_data = pd.DataFrame({\n",
    "        'Null Count': null_counts,\n",
    "        'Null Percentage': null_percentage\n",
    "    })\n",
    "    return null_data\n",
    "\n",
    "# Missing data for each column individually\n",
    "null_summary_df = null_summary(df_filtered)\n",
    "print(null_summary_df)\n",
    "\n",
    "# Missing data in the whole data matrix\n",
    "total_missing_percentage = df_filtered.isnull().sum().sum() / (df_filtered.size) * 100\n",
    "print(\"Total missing data (%): \", total_missing_percentage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
